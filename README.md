# Museum-Exhibit-Robot

Objective: This code enables wireless communication between a museum visitor console and robotic exhibit component. The original purpose was to give visitors control over a physical robot in the exhibit (Code A) such that they could light it up, make sounds, and choose movement destinations. I changed the code when the exhibit became mostly digital such that the communication was between the exhibit itself and the user with a physical robot in front of them (Code B). This communication was designed to have the robot hardware represent the visitor’s interaction in the digital exhibit and vice versa, where the visitor’s interactions with the physical robot, such as customizing its look, would be represented in the digital exhibit.

Description: In both programs, an Arduino with an ESP32 WiFi module is hosting a web page, and communication is done through that page on a different device. The web page is designed with HTML and CSS through the Arduino itself.

IoT_Robot_Controller: Using HTML and CSS, I designed a simple web page with button controls. Each button changes the url, triggering a handle function on the robot. For LED control and the buzzer, this function simply turns them on and off. For translational movement and head turning, the handle function holds the motor control. What I love about this project is that a user can control the robot just from their phone, although the exhibit was designed to be a tablet on the robot’s web page. First the device is connected to the robot’s WiFi Network via unique SSID and password. Once on the network, the user can access the web page via the robot’s IP address.

IoT_Sensors_Comms: With the project being redefined, I had to make some major changes to the code. Now instead of the user controlling a robot from a web page, the web page needed to send data back and forth between the digital component of the exhibit and the robot. Users could attach physical tools to the robot which I detected with an ohm meter (each connected via a unique resistor). The location and type of tool chosen was then published to the webpage for the digital exhibit to parse. The digital exhibit then made a call to the robot’s web page, triggering a handle function to light up a certain number of LEDs that represent how many points the visitor earned in the exhibit.
